{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q evaluate transformers[torch]","metadata":{"execution":{"iopub.status.busy":"2024-02-05T13:59:25.934142Z","iopub.execute_input":"2024-02-05T13:59:25.934440Z","iopub.status.idle":"2024-02-05T13:59:41.750662Z","shell.execute_reply.started":"2024-02-05T13:59:25.934413Z","shell.execute_reply":"2024-02-05T13:59:41.749530Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Load a dataset from Hugging Face\nfrom datasets import load_dataset\n\nhf_dataset_identifier = \"jacquelinegrimm/arabidopsis-kmeans\"\nds = load_dataset(hf_dataset_identifier)","metadata":{"execution":{"iopub.status.busy":"2024-02-05T13:59:52.248098Z","iopub.execute_input":"2024-02-05T13:59:52.248755Z","iopub.status.idle":"2024-02-05T13:59:57.001430Z","shell.execute_reply.started":"2024-02-05T13:59:52.248718Z","shell.execute_reply":"2024-02-05T13:59:57.000468Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Downloading and preparing dataset parquet/jacquelinegrimm--arabidopsis-kmeans to /root/.cache/huggingface/datasets/parquet/jacquelinegrimm--arabidopsis-kmeans-dc8875be3ba5f03a/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24bfa3950cbe4e18952084c1f126a91d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/49.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3235715fd4d4976b1123dd0bd72affb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13515fed71b74202879ee5792e96e9df"}},"metadata":{}},{"name":"stdout","text":"Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/parquet/jacquelinegrimm--arabidopsis-kmeans-dc8875be3ba5f03a/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7b699b5dda44fadb57b18e15f560022"}},"metadata":{}}]},{"cell_type":"code","source":"# Shuffle and split the dataset into training and test sets\n\nds = ds.shuffle(seed=1) # The 'seed' parameter is set to 1 for reproducibility\nds = ds[\"train\"].train_test_split(test_size=0.2)\n\ntrain_ds = ds[\"train\"]\ntest_ds = ds[\"test\"]","metadata":{"execution":{"iopub.status.busy":"2024-02-05T14:00:07.545665Z","iopub.execute_input":"2024-02-05T14:00:07.546755Z","iopub.status.idle":"2024-02-05T14:00:07.624323Z","shell.execute_reply.started":"2024-02-05T14:00:07.546717Z","shell.execute_reply":"2024-02-05T14:00:07.623483Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import json\nfrom huggingface_hub import hf_hub_download","metadata":{"execution":{"iopub.status.busy":"2024-02-05T14:00:16.818711Z","iopub.execute_input":"2024-02-05T14:00:16.819110Z","iopub.status.idle":"2024-02-05T14:00:16.823839Z","shell.execute_reply.started":"2024-02-05T14:00:16.819077Z","shell.execute_reply":"2024-02-05T14:00:16.822768Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# To configure the model, extract the number of unique labels\n\nrepo_id = f\"datasets/{hf_dataset_identifier}\"\nfilename = \"id2label.json\" # Define the filename containing label information\n\n# Download the 'id2label.json' file\nid2label = json.load(open(hf_hub_download(repo_id=hf_dataset_identifier, filename=filename, repo_type=\"dataset\"), \"r\"))\n\n# Convert the keys in 'id2label' from strings to integers and store the result in 'id2label'\nid2label = {int(k): v for k, v in id2label.items()}\n\n# Create a 'label2id' dictionary by reversing the key-value pairs in 'id2label'\nlabel2id = {v: k for k, v in id2label.items()}\n\n# Calculate the number of unique labels in the dataset\nnum_labels = len(id2label)","metadata":{"execution":{"iopub.status.busy":"2024-02-05T14:00:57.892851Z","iopub.execute_input":"2024-02-05T14:00:57.893241Z","iopub.status.idle":"2024-02-05T14:00:58.033765Z","shell.execute_reply.started":"2024-02-05T14:00:57.893211Z","shell.execute_reply":"2024-02-05T14:00:58.032957Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"id2label.json:   0%|          | 0.00/36.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7afe74e28d4c4dbd90af468b60e2c6b8"}},"metadata":{}}]},{"cell_type":"code","source":"from torchvision.transforms import ColorJitter\nfrom transformers import SegformerImageProcessor","metadata":{"execution":{"iopub.status.busy":"2024-02-05T14:01:06.886597Z","iopub.execute_input":"2024-02-05T14:01:06.886950Z","iopub.status.idle":"2024-02-05T14:01:32.205178Z","shell.execute_reply.started":"2024-02-05T14:01:06.886922Z","shell.execute_reply":"2024-02-05T14:01:32.204371Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5aec8ecbb474df58d5acd1bee3ec9be"}},"metadata":{}},{"name":"stderr","text":"2024-02-05 14:01:20.005490: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-05 14:01:20.005587: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-05 14:01:20.297354: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"# Transform data to match the model's expected input shape and perform image augmentation\n# Apply color jitter, which introduces random variations in brightness, contrast, saturation, and hue\n\nprocessor = SegformerImageProcessor()\njitter = ColorJitter(brightness=0.25, contrast=0.25, saturation=0.25, hue=0.1)\n\n# Function to apply transformations to a batch of training examples\ndef train_transforms(example_batch):\n\n    # Apply color jitter to each image in the batch\n    images = [jitter(x) for x in example_batch['pixel_values']]\n    # Extract labels from the batch\n    labels = [x for x in example_batch['label']]\n    # Use the processor to transform images and labels to match the expected input shape\n    inputs = processor(images, labels)\n    # Return the transformed inputs\n    return inputs\n\n# Function to apply transformations to a batch of validation examples\ndef val_transforms(example_batch):\n\n    # Extract images from the batch without applying color jitter\n    images = [x for x in example_batch['pixel_values']]\n    # Extract labels from the batch\n    labels = [x for x in example_batch['label']]\n    # Use the processor to transform images and labels to match the expected input shape\n    inputs = processor(images, labels)\n    # Return the transformed inputs\n    return inputs\n\n# Set the transformation functions for the training and testing datasets\ntrain_ds.set_transform(train_transforms)\ntest_ds.set_transform(val_transforms)","metadata":{"execution":{"iopub.status.busy":"2024-02-05T14:02:26.586926Z","iopub.execute_input":"2024-02-05T14:02:26.587636Z","iopub.status.idle":"2024-02-05T14:02:26.598564Z","shell.execute_reply.started":"2024-02-05T14:02:26.587596Z","shell.execute_reply":"2024-02-05T14:02:26.597408Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Load the semantic segmentation model\nfrom transformers import SegformerForSemanticSegmentation\n\npretrained_model_name = \"jacquelinegrimm/segformer-b0-finetuned-arabidopsis-roots-v02\" \n\nmodel = SegformerForSemanticSegmentation.from_pretrained(\n    pretrained_model_name,\n    id2label=id2label,\n    label2id=label2id\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-05T14:02:40.768500Z","iopub.execute_input":"2024-02-05T14:02:40.769117Z","iopub.status.idle":"2024-02-05T14:02:42.319348Z","shell.execute_reply.started":"2024-02-05T14:02:40.769084Z","shell.execute_reply":"2024-02-05T14:02:42.318419Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.11k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f7e3cc2c43146e9a8ec0e990cc3bfcf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/14.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6633a210caf94fc488fd1a4d929da28b"}},"metadata":{}}]},{"cell_type":"code","source":"# Specify training arguments and name the fine-tuned model\nfrom transformers import TrainingArguments\n\n# Define training hyperparameters\nepochs = 50\nlr = 0.00006\nbatch_size = 2\n\nhub_model_id = \"segformer-b0-finetuned-arabidopsis-roots-v03\" # Name the fine-tuned model\n\ntraining_args = TrainingArguments(\n    \"segformer-b0-finetuned-arabidopsis-roots-v03-outputs\",  # Name the output directory\n    learning_rate=lr,\n    num_train_epochs=epochs,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    save_total_limit=3,\n    evaluation_strategy=\"steps\",\n    save_strategy=\"steps\",\n    save_steps=20,\n    eval_steps=20,\n    logging_steps=1,\n    eval_accumulation_steps=5,\n    load_best_model_at_end=True,\n    push_to_hub=True,\n    hub_model_id=hub_model_id,\n    hub_strategy=\"end\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-05T14:02:56.343495Z","iopub.execute_input":"2024-02-05T14:02:56.344359Z","iopub.status.idle":"2024-02-05T14:02:56.425732Z","shell.execute_reply.started":"2024-02-05T14:02:56.344324Z","shell.execute_reply":"2024-02-05T14:02:56.424431Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Define mean intersection over union (IoU) as the evaluation metric\nimport torch\nfrom torch import nn\nimport evaluate\n\nmetric = evaluate.load(\"mean_iou\")\n\n# Function to calculate evaluation metrics for model predictions\ndef compute_metrics(eval_pred):\n    with torch.no_grad():\n        logits, labels = eval_pred\n\n        # Convert 'logits' into a tensor and resize it to match the shape of \"labels\"\n        logits_tensor = torch.from_numpy(logits)\n        logits_tensor = nn.functional.interpolate(\n            logits_tensor,\n            size=labels.shape[-2:],\n            mode=\"bilinear\",\n            align_corners=False,\n        ).argmax(dim=1)\n\n        # Convert the predicted labels to a NumPy array\n        pred_labels = logits_tensor.detach().cpu().numpy()\n\n        # Calculate metrics using the 'mean_iou' evaluation metric\n        metrics = metric._compute(\n            predictions=pred_labels,\n            references=labels,\n            num_labels=len(id2label),  # Number of unique labels in the dataset\n            ignore_index=0,\n            reduce_labels=processor.do_reduce_labels,\n        )\n\n        # Extract per-category accuracy and IoU scores\n        per_category_accuracy = metrics.pop(\"per_category_accuracy\").tolist()\n        per_category_iou = metrics.pop(\"per_category_iou\").tolist()\n\n        # Update the metrics dictionary with accuracy and IoU scores for each category\n        metrics.update({f\"accuracy_{id2label[i]}\": v for i, v in enumerate(per_category_accuracy)})\n        metrics.update({f\"iou_{id2label[i]}\": v for i, v in enumerate(per_category_iou)})\n\n        return metrics","metadata":{"execution":{"iopub.status.busy":"2024-02-05T14:03:17.723026Z","iopub.execute_input":"2024-02-05T14:03:17.723653Z","iopub.status.idle":"2024-02-05T14:03:21.547822Z","shell.execute_reply.started":"2024-02-05T14:03:17.723621Z","shell.execute_reply":"2024-02-05T14:03:21.546937Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/13.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef0814992eab4eef8d0c7cc1af9990da"}},"metadata":{}}]},{"cell_type":"code","source":"# Log in to Hugging Face\nfrom huggingface_hub import notebook_login\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-02-05T14:03:31.492850Z","iopub.execute_input":"2024-02-05T14:03:31.493655Z","iopub.status.idle":"2024-02-05T14:03:31.521747Z","shell.execute_reply.started":"2024-02-05T14:03:31.493621Z","shell.execute_reply":"2024-02-05T14:03:31.520806Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e83482279e545e195c19fb1e1ae0db9"}},"metadata":{}}]},{"cell_type":"code","source":"# Train the model\nfrom transformers import Trainer\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_ds,\n    eval_dataset=test_ds,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-02-05T14:03:55.461724Z","iopub.execute_input":"2024-02-05T14:03:55.462121Z","iopub.status.idle":"2024-02-05T14:41:56.295493Z","shell.execute_reply.started":"2024-02-05T14:03:55.462090Z","shell.execute_reply":"2024-02-05T14:41:56.294489Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.2"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240205_140414-1d3x0k0l</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/jacquelinekgrimm/huggingface/runs/1d3x0k0l' target=\"_blank\">sleek-frost-15</a></strong> to <a href='https://wandb.ai/jacquelinekgrimm/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/jacquelinekgrimm/huggingface' target=\"_blank\">https://wandb.ai/jacquelinekgrimm/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/jacquelinekgrimm/huggingface/runs/1d3x0k0l' target=\"_blank\">https://wandb.ai/jacquelinekgrimm/huggingface/runs/1d3x0k0l</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='400' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [400/400 36:50, Epoch 50/50]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Mean Iou</th>\n      <th>Mean Accuracy</th>\n      <th>Overall Accuracy</th>\n      <th>Accuracy Background</th>\n      <th>Accuracy Seedling</th>\n      <th>Iou Background</th>\n      <th>Iou Seedling</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>20</td>\n      <td>0.047700</td>\n      <td>0.037365</td>\n      <td>0.432796</td>\n      <td>0.865593</td>\n      <td>0.865593</td>\n      <td>nan</td>\n      <td>0.865593</td>\n      <td>0.000000</td>\n      <td>0.865593</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.035500</td>\n      <td>0.033744</td>\n      <td>0.443057</td>\n      <td>0.886114</td>\n      <td>0.886114</td>\n      <td>nan</td>\n      <td>0.886114</td>\n      <td>0.000000</td>\n      <td>0.886114</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.039100</td>\n      <td>0.032790</td>\n      <td>0.441585</td>\n      <td>0.883170</td>\n      <td>0.883170</td>\n      <td>nan</td>\n      <td>0.883170</td>\n      <td>0.000000</td>\n      <td>0.883170</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.033900</td>\n      <td>0.030588</td>\n      <td>0.439179</td>\n      <td>0.878358</td>\n      <td>0.878358</td>\n      <td>nan</td>\n      <td>0.878358</td>\n      <td>0.000000</td>\n      <td>0.878358</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.024800</td>\n      <td>0.029996</td>\n      <td>0.438913</td>\n      <td>0.877826</td>\n      <td>0.877826</td>\n      <td>nan</td>\n      <td>0.877826</td>\n      <td>0.000000</td>\n      <td>0.877826</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.037500</td>\n      <td>0.028461</td>\n      <td>0.427793</td>\n      <td>0.855586</td>\n      <td>0.855586</td>\n      <td>nan</td>\n      <td>0.855586</td>\n      <td>0.000000</td>\n      <td>0.855586</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.046300</td>\n      <td>0.028781</td>\n      <td>0.430205</td>\n      <td>0.860410</td>\n      <td>0.860410</td>\n      <td>nan</td>\n      <td>0.860410</td>\n      <td>0.000000</td>\n      <td>0.860410</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.023700</td>\n      <td>0.033380</td>\n      <td>0.411632</td>\n      <td>0.823265</td>\n      <td>0.823265</td>\n      <td>nan</td>\n      <td>0.823265</td>\n      <td>0.000000</td>\n      <td>0.823265</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.030900</td>\n      <td>0.027662</td>\n      <td>0.428238</td>\n      <td>0.856477</td>\n      <td>0.856477</td>\n      <td>nan</td>\n      <td>0.856477</td>\n      <td>0.000000</td>\n      <td>0.856477</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.023700</td>\n      <td>0.029923</td>\n      <td>0.424521</td>\n      <td>0.849043</td>\n      <td>0.849043</td>\n      <td>nan</td>\n      <td>0.849043</td>\n      <td>0.000000</td>\n      <td>0.849043</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>0.041500</td>\n      <td>0.026928</td>\n      <td>0.431708</td>\n      <td>0.863416</td>\n      <td>0.863416</td>\n      <td>nan</td>\n      <td>0.863416</td>\n      <td>0.000000</td>\n      <td>0.863416</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>0.055700</td>\n      <td>0.027288</td>\n      <td>0.421831</td>\n      <td>0.843662</td>\n      <td>0.843662</td>\n      <td>nan</td>\n      <td>0.843662</td>\n      <td>0.000000</td>\n      <td>0.843662</td>\n    </tr>\n    <tr>\n      <td>260</td>\n      <td>0.025100</td>\n      <td>0.026765</td>\n      <td>0.430576</td>\n      <td>0.861152</td>\n      <td>0.861152</td>\n      <td>nan</td>\n      <td>0.861152</td>\n      <td>0.000000</td>\n      <td>0.861152</td>\n    </tr>\n    <tr>\n      <td>280</td>\n      <td>0.028300</td>\n      <td>0.026843</td>\n      <td>0.437769</td>\n      <td>0.875538</td>\n      <td>0.875538</td>\n      <td>nan</td>\n      <td>0.875538</td>\n      <td>0.000000</td>\n      <td>0.875538</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.031000</td>\n      <td>0.027786</td>\n      <td>0.429147</td>\n      <td>0.858295</td>\n      <td>0.858295</td>\n      <td>nan</td>\n      <td>0.858295</td>\n      <td>0.000000</td>\n      <td>0.858295</td>\n    </tr>\n    <tr>\n      <td>320</td>\n      <td>0.025600</td>\n      <td>0.029337</td>\n      <td>0.419858</td>\n      <td>0.839716</td>\n      <td>0.839716</td>\n      <td>nan</td>\n      <td>0.839716</td>\n      <td>0.000000</td>\n      <td>0.839716</td>\n    </tr>\n    <tr>\n      <td>340</td>\n      <td>0.035800</td>\n      <td>0.027171</td>\n      <td>0.429098</td>\n      <td>0.858196</td>\n      <td>0.858196</td>\n      <td>nan</td>\n      <td>0.858196</td>\n      <td>0.000000</td>\n      <td>0.858196</td>\n    </tr>\n    <tr>\n      <td>360</td>\n      <td>0.024600</td>\n      <td>0.027032</td>\n      <td>0.433062</td>\n      <td>0.866125</td>\n      <td>0.866125</td>\n      <td>nan</td>\n      <td>0.866125</td>\n      <td>0.000000</td>\n      <td>0.866125</td>\n    </tr>\n    <tr>\n      <td>380</td>\n      <td>0.019400</td>\n      <td>0.026400</td>\n      <td>0.437386</td>\n      <td>0.874771</td>\n      <td>0.874771</td>\n      <td>nan</td>\n      <td>0.874771</td>\n      <td>0.000000</td>\n      <td>0.874771</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.043700</td>\n      <td>0.026705</td>\n      <td>0.433761</td>\n      <td>0.867523</td>\n      <td>0.867523</td>\n      <td>nan</td>\n      <td>0.867523</td>\n      <td>0.000000</td>\n      <td>0.867523</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/root/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/08bc20f4f895f3caf75fb9e3fada1404bded3c3265243d05327cbb3b9326ffe9/mean_iou.py:260: RuntimeWarning: invalid value encountered in divide\n  acc = total_area_intersect / total_area_label\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/root/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/08bc20f4f895f3caf75fb9e3fada1404bded3c3265243d05327cbb3b9326ffe9/mean_iou.py:260: RuntimeWarning: invalid value encountered in divide\n  acc = total_area_intersect / total_area_label\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/root/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/08bc20f4f895f3caf75fb9e3fada1404bded3c3265243d05327cbb3b9326ffe9/mean_iou.py:260: RuntimeWarning: invalid value encountered in divide\n  acc = total_area_intersect / total_area_label\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/root/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/08bc20f4f895f3caf75fb9e3fada1404bded3c3265243d05327cbb3b9326ffe9/mean_iou.py:260: RuntimeWarning: invalid value encountered in divide\n  acc = total_area_intersect / total_area_label\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/root/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/08bc20f4f895f3caf75fb9e3fada1404bded3c3265243d05327cbb3b9326ffe9/mean_iou.py:260: RuntimeWarning: invalid value encountered in divide\n  acc = total_area_intersect / total_area_label\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/root/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/08bc20f4f895f3caf75fb9e3fada1404bded3c3265243d05327cbb3b9326ffe9/mean_iou.py:260: RuntimeWarning: invalid value encountered in divide\n  acc = total_area_intersect / total_area_label\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/root/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/08bc20f4f895f3caf75fb9e3fada1404bded3c3265243d05327cbb3b9326ffe9/mean_iou.py:260: RuntimeWarning: invalid value encountered in divide\n  acc = total_area_intersect / total_area_label\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/root/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/08bc20f4f895f3caf75fb9e3fada1404bded3c3265243d05327cbb3b9326ffe9/mean_iou.py:260: RuntimeWarning: invalid value encountered in divide\n  acc = total_area_intersect / total_area_label\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/root/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/08bc20f4f895f3caf75fb9e3fada1404bded3c3265243d05327cbb3b9326ffe9/mean_iou.py:260: RuntimeWarning: invalid value encountered in divide\n  acc = total_area_intersect / total_area_label\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/root/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/08bc20f4f895f3caf75fb9e3fada1404bded3c3265243d05327cbb3b9326ffe9/mean_iou.py:260: RuntimeWarning: invalid value encountered in divide\n  acc = total_area_intersect / total_area_label\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/root/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/08bc20f4f895f3caf75fb9e3fada1404bded3c3265243d05327cbb3b9326ffe9/mean_iou.py:260: RuntimeWarning: invalid value encountered in divide\n  acc = total_area_intersect / total_area_label\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/root/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/08bc20f4f895f3caf75fb9e3fada1404bded3c3265243d05327cbb3b9326ffe9/mean_iou.py:260: RuntimeWarning: invalid value encountered in divide\n  acc = total_area_intersect / total_area_label\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/root/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/08bc20f4f895f3caf75fb9e3fada1404bded3c3265243d05327cbb3b9326ffe9/mean_iou.py:260: RuntimeWarning: invalid value encountered in divide\n  acc = total_area_intersect / total_area_label\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/root/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/08bc20f4f895f3caf75fb9e3fada1404bded3c3265243d05327cbb3b9326ffe9/mean_iou.py:260: RuntimeWarning: invalid value encountered in divide\n  acc = total_area_intersect / total_area_label\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/root/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/08bc20f4f895f3caf75fb9e3fada1404bded3c3265243d05327cbb3b9326ffe9/mean_iou.py:260: RuntimeWarning: invalid value encountered in divide\n  acc = total_area_intersect / total_area_label\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/root/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/08bc20f4f895f3caf75fb9e3fada1404bded3c3265243d05327cbb3b9326ffe9/mean_iou.py:260: RuntimeWarning: invalid value encountered in divide\n  acc = total_area_intersect / total_area_label\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/root/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/08bc20f4f895f3caf75fb9e3fada1404bded3c3265243d05327cbb3b9326ffe9/mean_iou.py:260: RuntimeWarning: invalid value encountered in divide\n  acc = total_area_intersect / total_area_label\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/root/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/08bc20f4f895f3caf75fb9e3fada1404bded3c3265243d05327cbb3b9326ffe9/mean_iou.py:260: RuntimeWarning: invalid value encountered in divide\n  acc = total_area_intersect / total_area_label\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/root/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/08bc20f4f895f3caf75fb9e3fada1404bded3c3265243d05327cbb3b9326ffe9/mean_iou.py:260: RuntimeWarning: invalid value encountered in divide\n  acc = total_area_intersect / total_area_label\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/root/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/08bc20f4f895f3caf75fb9e3fada1404bded3c3265243d05327cbb3b9326ffe9/mean_iou.py:260: RuntimeWarning: invalid value encountered in divide\n  acc = total_area_intersect / total_area_label\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=400, training_loss=0.03607273187022656, metrics={'train_runtime': 2278.3185, 'train_samples_per_second': 0.702, 'train_steps_per_second': 0.176, 'total_flos': 2.80447288344576e+16, 'train_loss': 0.03607273187022656, 'epoch': 50.0})"},"metadata":{}}]},{"cell_type":"code","source":"# Push the fine-tuned model to Hugging Face\nkwargs = {\n    \"tags\": [\"vision\", \"image-segmentation\"],\n    \"finetuned_from\": pretrained_model_name,\n    \"dataset\": hf_dataset_identifier,\n}\n\nprocessor.push_to_hub(hub_model_id)\ntrainer.push_to_hub(**kwargs)","metadata":{"execution":{"iopub.status.busy":"2024-02-05T14:43:33.134302Z","iopub.execute_input":"2024-02-05T14:43:33.135052Z","iopub.status.idle":"2024-02-05T14:43:37.603844Z","shell.execute_reply.started":"2024-02-05T14:43:33.135014Z","shell.execute_reply":"2024-02-05T14:43:37.602114Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"training_args.bin:   0%|          | 0.00/4.79k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29c1c4956c4746feb78c3fa0e7106104"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/14.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdd950e69e4c4420a1f9b3536589f022"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1707141837.0a092a314f00.35.0:   0%|          | 0.00/81.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"154fe9bdda6d4e9681aee63ffb4e0aee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload 3 LFS files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5f120f0592b47728927de81496cc88c"}},"metadata":{}},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/jacquelinegrimm/segformer-b0-finetuned-arabidopsis-roots-v03/commit/41e902f171e8da3858044acc5f254630ea41e67b', commit_message='End of training', commit_description='', oid='41e902f171e8da3858044acc5f254630ea41e67b', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}